
> [!info] Status
> **Status:** Complete

# In-Depth: Image Convolution

This note provides a detailed explanation of image convolution, a fundamental operation in image processing used for applying filters to images.

## Referenced In
- [[../02 Image Preprocessing and Filtering/2.1 Spatial Domain vs Frequency Domain|Spatial vs Frequency Domain]]
- [[../02 Image Preprocessing and Filtering/2.2 Linear Spatial Filters (Mean, Gaussian)|Linear Spatial Filters]]
- [[../02 Image Preprocessing and Filtering/2.3 Non-Linear Spatial Filters (Median, Nagao)|Non-Linear Spatial Filters]]

## Core Concept

Image convolution is an operation where each output pixel's value is calculated as a weighted sum of the corresponding input pixel and its neighbors. The process involves sliding a small matrix, known as a **kernel** or **filter**, over the entire input image. At each position, an element-wise multiplication between the kernel and the overlapping image neighborhood is performed, and the results are summed to produce the value for the output pixel.

This "sliding window" mechanism allows the kernel to systematically modify the image based on local pixel information, making it the primary method for tasks like blurring, sharpening, edge detection, and noise reduction.

## The Kernel (Filter/Mask)

The kernel is the small matrix of weights that defines the effect of the convolution. The values and size of the kernel determine the outcome of the filtering operation.

### Key Properties
-   **Size:** Kernels typically have odd dimensions (e.g., 3x3, 5x5, 7x7). This ensures that the kernel has a clear center, which aligns with the current pixel being processed in the input image.
-   **Symmetry:** Many common kernels are symmetric, meaning the weights are balanced around the center.
-   **Sum of Elements:** The sum of the kernel's elements often has significance. For example, in blurring filters, the elements typically sum to 1 to preserve the overall brightness of the image.

## Mathematical Definition

The convolution operation is denoted by the `⊗` symbol. For an input image `f(x,y)` and a filter `h(x,y)`, the resulting image `g(x,y)` is:

`g(x,y) = f(x,y) ⊗ h(x,y)`

In discrete terms, this is calculated using a double summation. For a pixel at `(x,y)`, the value is computed as:

`g(x, y) = Σ Σ f(x + i, y + j) ⋅ h(i, j)`

Where `i` and `j` are the indices iterating over the dimensions of the kernel `h`.

## The Convolution Process: Step-by-Step

1.  **Select an Output Pixel:** Choose a coordinate `(x,y)` in the output image to calculate.
2.  **Center the Kernel:** Place the center of the kernel over the corresponding coordinate `(x,y)` in the input image.
3.  **Element-Wise Multiplication:** Multiply each element of the kernel by the value of the underlying pixel in the input image.
4.  **Summation:** Sum all the products from the previous step.
5.  **Assign Value:** The resulting sum is the new value for the output pixel at `(x,y)`.
6.  **Repeat:** Repeat this process for every pixel in the image.

## Properties of Convolution

Convolution has several mathematical properties that are important in image processing:

-   **Commutativity:** `f ⊗ h = h ⊗ f`
    -   The order of the image and the filter does not matter.
-   **Associativity:** `(f ⊗ h1) ⊗ h2 = f ⊗ (h1 ⊗ h2)`
    -   Applying two filters sequentially is the same as applying a single filter that is the convolution of the two individual filters.
-   **Distributivity:** `f ⊗ (h1 + h2) = (f ⊗ h1) + (f ⊗ h2)`
    -   Applying a filter that is the sum of two other filters is the same as applying each filter individually and summing the results.
-   **Separability:** A 2D kernel `h(x,y)` is separable if it can be expressed as the product of two 1D vectors: `h(x,y) = hx(x) * hy(y)`.
    -   **Insight:** This property is extremely valuable for optimization. Instead of a single 2D convolution, one can perform two much faster 1D convolutions (one along the rows, one along the columns). This significantly reduces computational complexity, especially for large kernels.

## Handling Image Borders (Edge Effects)

When the kernel is positioned over pixels at the edge of the image, part of the kernel will extend beyond the image boundary. There are several common strategies to handle this:

1.  **Do Not Filter Borders (Cropping):** The simplest method is to not calculate new values for the border pixels. The output image will be slightly smaller than the input.
2.  **Padding with Zeros:** The input image is extended by adding a border of black pixels (value 0). This allows the kernel to operate on all original pixels but can introduce a dark edge artifact.
3.  **Mirror Padding (Reflection):** The border is extended by reflecting the pixel values from within the image. This is often a more effective method as it maintains a more natural transition at the edges and reduces artifacts.

## Keywords

| Keyword                 | Description                                                                                             |
| ----------------------- | ------------------------------------------------------------------------------------------------------- |
| [[Convolution]]         | The mathematical operation of sliding a kernel over an image to apply a filter.                         |
| [[Kernel]]              | A small matrix of weights that defines the filter's effect.                                             |
| [[Spatial Filtering]]   | Filtering operations that work directly on the pixel grid.                                              |
| [[Padding]]             | The process of handling image borders during convolution (e.g., zero-padding, mirror padding).          |
| [[Separable Filter]]    | A 2D filter that can be optimized by decomposing it into two 1D filters.                                |

---
tags: #in-depth #convolution #kernel #spatial-filtering